22/10/20 18:15:49 WARN Utils: Your hostname, 1011000011101110 resolves to a loopback address: 127.0.1.1; using 192.168.1.72 instead (on interface wlp3s0)
22/10/20 18:15:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
22/10/20 18:15:51 INFO SparkContext: Running Spark version 3.3.0
22/10/20 18:15:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/10/20 18:15:52 INFO ResourceUtils: ==============================================================
22/10/20 18:15:52 INFO ResourceUtils: No custom resources configured for spark.driver.
22/10/20 18:15:52 INFO ResourceUtils: ==============================================================
22/10/20 18:15:52 INFO SparkContext: Submitted application: Walmart Ecommerce
22/10/20 18:15:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/10/20 18:15:52 INFO ResourceProfile: Limiting resource is cpu
22/10/20 18:15:52 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/10/20 18:15:52 INFO SecurityManager: Changing view acls to: prasag
22/10/20 18:15:52 INFO SecurityManager: Changing modify acls to: prasag
22/10/20 18:15:52 INFO SecurityManager: Changing view acls groups to: 
22/10/20 18:15:52 INFO SecurityManager: Changing modify acls groups to: 
22/10/20 18:15:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(prasag); groups with view permissions: Set(); users  with modify permissions: Set(prasag); groups with modify permissions: Set()
22/10/20 18:15:52 INFO Utils: Successfully started service 'sparkDriver' on port 39985.
22/10/20 18:15:52 INFO SparkEnv: Registering MapOutputTracker
22/10/20 18:15:52 INFO SparkEnv: Registering BlockManagerMaster
22/10/20 18:15:52 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/10/20 18:15:52 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/10/20 18:15:52 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/10/20 18:15:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-113114f0-9409-4d51-9ee9-e8abc410a5b4
22/10/20 18:15:53 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
22/10/20 18:15:53 INFO SparkEnv: Registering OutputCommitCoordinator
22/10/20 18:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
22/10/20 18:15:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
22/10/20 18:15:53 INFO Utils: Successfully started service 'SparkUI' on port 4042.
22/10/20 18:15:53 INFO Executor: Starting executor ID driver on host 192.168.1.72
22/10/20 18:15:53 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
22/10/20 18:15:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39637.
22/10/20 18:15:53 INFO NettyBlockTransferService: Server created on 192.168.1.72:39637
22/10/20 18:15:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/10/20 18:15:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.72, 39637, None)
22/10/20 18:15:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.72:39637 with 434.4 MiB RAM, BlockManagerId(driver, 192.168.1.72, 39637, None)
22/10/20 18:15:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.72, 39637, None)
22/10/20 18:15:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.72, 39637, None)
22/10/20 18:15:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
22/10/20 18:15:54 INFO SharedState: Warehouse path is 'file:/home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/spark-warehouse'.
22/10/20 18:15:55 INFO InMemoryFileIndex: It took 94 ms to list leaf files for 1 paths.
22/10/20 18:15:56 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 1 paths.
22/10/20 18:15:59 INFO FileSourceStrategy: Pushed Filters: 
22/10/20 18:15:59 INFO FileSourceStrategy: Post-Scan Filters: 
22/10/20 18:15:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
22/10/20 18:15:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.1 KiB, free 434.2 MiB)
22/10/20 18:16:00 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 434.2 MiB)
22/10/20 18:16:00 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.1.72:39637 (size: 34.0 KiB, free: 434.4 MiB)
22/10/20 18:16:00 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
22/10/20 18:16:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:00 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
22/10/20 18:16:00 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 4 output partitions
22/10/20 18:16:00 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
22/10/20 18:16:00 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:00 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:00 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
22/10/20 18:16:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.5 KiB, free 434.2 MiB)
22/10/20 18:16:00 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.0 KiB, free 434.2 MiB)
22/10/20 18:16:00 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.1.72:39637 (size: 7.0 KiB, free: 434.4 MiB)
22/10/20 18:16:00 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:00 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:00 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks resource profile 0
22/10/20 18:16:00 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:00 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:00 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:00 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:00 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
22/10/20 18:16:00 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
22/10/20 18:16:00 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
22/10/20 18:16:00 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
22/10/20 18:16:01 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:01 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:01 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:01 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:01 INFO CodeGenerator: Code generated in 356.851646 ms
22/10/20 18:16:02 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2469 bytes result sent to driver
22/10/20 18:16:02 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 2137 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:03 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2391 bytes result sent to driver
22/10/20 18:16:03 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2705 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:03 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2391 bytes result sent to driver
22/10/20 18:16:03 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 2729 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2391 bytes result sent to driver
22/10/20 18:16:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2782 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
22/10/20 18:16:03 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 3.031 s
22/10/20 18:16:03 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
22/10/20 18:16:03 INFO DAGScheduler: Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 3.122059 s
22/10/20 18:16:04 INFO FileSourceStrategy: Pushed Filters: 
22/10/20 18:16:04 INFO FileSourceStrategy: Post-Scan Filters: 
22/10/20 18:16:04 INFO FileSourceStrategy: Output Data Schema: struct<Available: string, Brand: string, Category: string, Crawl Timestamp: string, Description: string ... 13 more fields>
22/10/20 18:16:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.0 KiB, free 434.0 MiB)
22/10/20 18:16:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 433.9 MiB)
22/10/20 18:16:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.3 MiB)
22/10/20 18:16:04 INFO SparkContext: Created broadcast 2 from toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13
22/10/20 18:16:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:04 INFO SparkContext: Starting job: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13
22/10/20 18:16:04 INFO DAGScheduler: Got job 1 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13) with 4 output partitions
22/10/20 18:16:04 INFO DAGScheduler: Final stage: ResultStage 1 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13)
22/10/20 18:16:04 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:04 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13), which has no missing parents
22/10/20 18:16:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.9 KiB, free 433.9 MiB)
22/10/20 18:16:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 433.9 MiB)
22/10/20 18:16:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.1.72:39637 (size: 5.7 KiB, free: 434.3 MiB)
22/10/20 18:16:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:04 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks resource profile 0
22/10/20 18:16:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 4) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:04 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 6) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:04 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4993 bytes) taskResourceAssignments Map()
22/10/20 18:16:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 4)
22/10/20 18:16:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 5)
22/10/20 18:16:04 INFO Executor: Running task 2.0 in stage 1.0 (TID 6)
22/10/20 18:16:04 INFO Executor: Running task 3.0 in stage 1.0 (TID 7)
22/10/20 18:16:04 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:04 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:04 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:04 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.1.72:39637 in memory (size: 7.0 KiB, free: 434.3 MiB)
22/10/20 18:16:04 INFO CodeGenerator: Code generated in 46.334176 ms
22/10/20 18:16:05 INFO MemoryStore: Block taskresult_7 stored as bytes in memory (estimated size 1029.0 KiB, free 432.9 MiB)
22/10/20 18:16:05 INFO BlockManagerInfo: Added taskresult_7 in memory on 192.168.1.72:39637 (size: 1029.0 KiB, free: 433.3 MiB)
22/10/20 18:16:05 INFO Executor: Finished task 3.0 in stage 1.0 (TID 7). 1053667 bytes result sent via BlockManager)
22/10/20 18:16:05 INFO TransportClientFactory: Successfully created connection to /192.168.1.72:39637 after 66 ms (0 ms spent in bootstraps)
22/10/20 18:16:06 INFO MemoryStore: Block taskresult_5 stored as bytes in memory (estimated size 1641.1 KiB, free 431.3 MiB)
22/10/20 18:16:06 INFO BlockManagerInfo: Added taskresult_5 in memory on 192.168.1.72:39637 (size: 1641.1 KiB, free: 431.7 MiB)
22/10/20 18:16:06 INFO Executor: Finished task 1.0 in stage 1.0 (TID 5). 1680458 bytes result sent via BlockManager)
22/10/20 18:16:06 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 7) in 1729 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:06 INFO MemoryStore: Block taskresult_6 stored as bytes in memory (estimated size 1482.6 KiB, free 430.9 MiB)
22/10/20 18:16:06 INFO BlockManagerInfo: Removed taskresult_7 on 192.168.1.72:39637 in memory (size: 1029.0 KiB, free: 432.7 MiB)
22/10/20 18:16:06 INFO BlockManagerInfo: Added taskresult_6 in memory on 192.168.1.72:39637 (size: 1482.6 KiB, free: 431.3 MiB)
22/10/20 18:16:06 INFO Executor: Finished task 2.0 in stage 1.0 (TID 6). 1518143 bytes result sent via BlockManager)
22/10/20 18:16:06 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 5) in 1765 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:06 INFO BlockManagerInfo: Removed taskresult_5 on 192.168.1.72:39637 in memory (size: 1641.1 KiB, free: 432.9 MiB)
22/10/20 18:16:06 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.1.72:39637 in memory (size: 34.0 KiB, free: 432.9 MiB)
22/10/20 18:16:06 INFO MemoryStore: Block taskresult_4 stored as bytes in memory (estimated size 1580.9 KiB, free 431.2 MiB)
22/10/20 18:16:06 INFO BlockManagerInfo: Added taskresult_4 in memory on 192.168.1.72:39637 (size: 1580.9 KiB, free: 431.4 MiB)
22/10/20 18:16:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 4). 1618883 bytes result sent via BlockManager)
22/10/20 18:16:06 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 6) in 1786 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:06 INFO BlockManagerInfo: Removed taskresult_6 on 192.168.1.72:39637 in memory (size: 1482.6 KiB, free: 432.8 MiB)
22/10/20 18:16:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 4) in 1801 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
22/10/20 18:16:06 INFO BlockManagerInfo: Removed taskresult_4 on 192.168.1.72:39637 in memory (size: 1580.9 KiB, free: 434.4 MiB)
22/10/20 18:16:06 INFO DAGScheduler: ResultStage 1 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13) finished in 1.828 s
22/10/20 18:16:06 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
22/10/20 18:16:06 INFO DAGScheduler: Job 1 finished: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:13, took 1.836252 s
22/10/20 18:16:06 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.1.72:39637 in memory (size: 5.7 KiB, free: 434.4 MiB)
22/10/20 18:16:09 INFO FileSourceStrategy: Pushed Filters: 
22/10/20 18:16:09 INFO FileSourceStrategy: Post-Scan Filters: 
22/10/20 18:16:09 INFO FileSourceStrategy: Output Data Schema: struct<Brand: string, Product Name: string>
22/10/20 18:16:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:10 INFO CodeGenerator: Code generated in 63.505296 ms
22/10/20 18:16:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 199.0 KiB, free 434.0 MiB)
22/10/20 18:16:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 433.9 MiB)
22/10/20 18:16:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.3 MiB)
22/10/20 18:16:10 INFO SparkContext: Created broadcast 4 from toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23
22/10/20 18:16:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:10 INFO DAGScheduler: Registering RDD 10 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23) as input to shuffle 0
22/10/20 18:16:10 INFO DAGScheduler: Got map stage job 2 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23) with 4 output partitions
22/10/20 18:16:10 INFO DAGScheduler: Final stage: ShuffleMapStage 2 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23)
22/10/20 18:16:10 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:10 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:10 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23), which has no missing parents
22/10/20 18:16:10 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 23.5 KiB, free 433.9 MiB)
22/10/20 18:16:10 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.1 KiB, free 433.9 MiB)
22/10/20 18:16:10 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.1.72:39637 (size: 11.1 KiB, free: 434.3 MiB)
22/10/20 18:16:10 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:10 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:10 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks resource profile 0
22/10/20 18:16:10 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 8) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:10 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 9) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:10 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 10) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:10 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 11) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:10 INFO Executor: Running task 1.0 in stage 2.0 (TID 9)
22/10/20 18:16:10 INFO Executor: Running task 0.0 in stage 2.0 (TID 8)
22/10/20 18:16:10 INFO Executor: Running task 2.0 in stage 2.0 (TID 10)
22/10/20 18:16:10 INFO Executor: Running task 3.0 in stage 2.0 (TID 11)
22/10/20 18:16:10 INFO CodeGenerator: Code generated in 72.18799 ms
22/10/20 18:16:10 INFO CodeGenerator: Code generated in 16.245553 ms
22/10/20 18:16:10 INFO CodeGenerator: Code generated in 21.025481 ms
22/10/20 18:16:10 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:10 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:10 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:10 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 9). 2813 bytes result sent to driver
22/10/20 18:16:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 8). 2813 bytes result sent to driver
22/10/20 18:16:11 INFO Executor: Finished task 2.0 in stage 2.0 (TID 10). 2813 bytes result sent to driver
22/10/20 18:16:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 8) in 1273 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:11 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 10) in 1270 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 9) in 1273 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:11 INFO Executor: Finished task 3.0 in stage 2.0 (TID 11). 2770 bytes result sent to driver
22/10/20 18:16:11 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 11) in 1277 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
22/10/20 18:16:11 INFO DAGScheduler: ShuffleMapStage 2 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23) finished in 1.333 s
22/10/20 18:16:11 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:11 INFO DAGScheduler: running: Set()
22/10/20 18:16:11 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:11 INFO DAGScheduler: failed: Set()
22/10/20 18:16:11 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
22/10/20 18:16:11 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:11 INFO CodeGenerator: Code generated in 33.744404 ms
22/10/20 18:16:11 INFO SparkContext: Starting job: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23
22/10/20 18:16:11 INFO DAGScheduler: Got job 3 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23) with 1 output partitions
22/10/20 18:16:11 INFO DAGScheduler: Final stage: ResultStage 4 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23)
22/10/20 18:16:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
22/10/20 18:16:11 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:11 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[13] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23), which has no missing parents
22/10/20 18:16:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 33.8 KiB, free 433.9 MiB)
22/10/20 18:16:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 15.6 KiB, free 433.9 MiB)
22/10/20 18:16:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.1.72:39637 (size: 15.6 KiB, free: 434.3 MiB)
22/10/20 18:16:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[13] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:11 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
22/10/20 18:16:11 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 12) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/10/20 18:16:11 INFO Executor: Running task 0.0 in stage 4.0 (TID 12)
22/10/20 18:16:12 INFO ShuffleBlockFetcherIterator: Getting 4 (393.5 KiB) non-empty blocks including 4 (393.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 31 ms
22/10/20 18:16:12 INFO Executor: Finished task 0.0 in stage 4.0 (TID 12). 271911 bytes result sent to driver
22/10/20 18:16:12 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 12) in 180 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:12 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
22/10/20 18:16:12 INFO DAGScheduler: ResultStage 4 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23) finished in 0.204 s
22/10/20 18:16:12 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
22/10/20 18:16:12 INFO DAGScheduler: Job 3 finished: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:23, took 0.247759 s
22/10/20 18:16:12 INFO FileSourceStrategy: Pushed Filters: IsNotNull(List Price),IsNotNull(Sale Price)
22/10/20 18:16:12 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(List Price#15),isnotnull(Sale Price#20),(List Price#15 > Sale Price#20)
22/10/20 18:16:12 INFO FileSourceStrategy: Output Data Schema: struct<List Price: string, Product Name: string, Sale Price: string ... 1 more fields>
22/10/20 18:16:12 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:12 INFO CodeGenerator: Code generated in 118.544653 ms
22/10/20 18:16:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 199.0 KiB, free 433.7 MiB)
22/10/20 18:16:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 433.6 MiB)
22/10/20 18:16:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.3 MiB)
22/10/20 18:16:12 INFO SparkContext: Created broadcast 7 from toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38
22/10/20 18:16:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:12 INFO DAGScheduler: Registering RDD 17 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38) as input to shuffle 1
22/10/20 18:16:12 INFO DAGScheduler: Got map stage job 4 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38) with 4 output partitions
22/10/20 18:16:12 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38)
22/10/20 18:16:12 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:12 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:12 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[17] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38), which has no missing parents
22/10/20 18:16:12 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 35.9 KiB, free 433.6 MiB)
22/10/20 18:16:12 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 433.6 MiB)
22/10/20 18:16:12 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.1.72:39637 (size: 16.8 KiB, free: 434.3 MiB)
22/10/20 18:16:12 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[17] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:12 INFO TaskSchedulerImpl: Adding task set 5.0 with 4 tasks resource profile 0
22/10/20 18:16:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 13) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:13 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 14) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:13 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 15) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:13 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 16) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:13 INFO Executor: Running task 0.0 in stage 5.0 (TID 13)
22/10/20 18:16:13 INFO Executor: Running task 1.0 in stage 5.0 (TID 14)
22/10/20 18:16:13 INFO Executor: Running task 3.0 in stage 5.0 (TID 16)
22/10/20 18:16:13 INFO Executor: Running task 2.0 in stage 5.0 (TID 15)
22/10/20 18:16:13 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.1.72:39637 in memory (size: 11.1 KiB, free: 434.3 MiB)
22/10/20 18:16:13 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.1.72:39637 in memory (size: 15.6 KiB, free: 434.3 MiB)
22/10/20 18:16:13 INFO CodeGenerator: Code generated in 44.359229 ms
22/10/20 18:16:13 INFO CodeGenerator: Code generated in 21.762635 ms
22/10/20 18:16:13 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:13 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:13 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:13 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:13 INFO CodeGenerator: Code generated in 23.656389 ms
22/10/20 18:16:13 INFO CodeGenerator: Code generated in 12.042646 ms
22/10/20 18:16:13 INFO CodeGenerator: Code generated in 8.173814 ms
22/10/20 18:16:13 INFO Executor: Finished task 3.0 in stage 5.0 (TID 16). 2783 bytes result sent to driver
22/10/20 18:16:13 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 16) in 578 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:13 INFO Executor: Finished task 0.0 in stage 5.0 (TID 13). 2783 bytes result sent to driver
22/10/20 18:16:13 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 13) in 656 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:13 INFO Executor: Finished task 2.0 in stage 5.0 (TID 15). 2783 bytes result sent to driver
22/10/20 18:16:13 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 15) in 690 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:13 INFO Executor: Finished task 1.0 in stage 5.0 (TID 14). 2783 bytes result sent to driver
22/10/20 18:16:13 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 14) in 700 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:13 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
22/10/20 18:16:13 INFO DAGScheduler: ShuffleMapStage 5 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38) finished in 0.726 s
22/10/20 18:16:13 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:13 INFO DAGScheduler: running: Set()
22/10/20 18:16:13 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:13 INFO DAGScheduler: failed: Set()
22/10/20 18:16:13 INFO ShufflePartitionsUtil: For shuffle(1), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
22/10/20 18:16:13 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:13 INFO CodeGenerator: Code generated in 28.862346 ms
22/10/20 18:16:13 INFO SparkContext: Starting job: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38
22/10/20 18:16:13 INFO DAGScheduler: Got job 5 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38) with 1 output partitions
22/10/20 18:16:13 INFO DAGScheduler: Final stage: ResultStage 7 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38)
22/10/20 18:16:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
22/10/20 18:16:13 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:13 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[20] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38), which has no missing parents
22/10/20 18:16:13 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 39.7 KiB, free 433.6 MiB)
22/10/20 18:16:13 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 18.1 KiB, free 433.6 MiB)
22/10/20 18:16:13 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.1.72:39637 (size: 18.1 KiB, free: 434.3 MiB)
22/10/20 18:16:13 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[20] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:13 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
22/10/20 18:16:13 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 17) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/10/20 18:16:13 INFO Executor: Running task 0.0 in stage 7.0 (TID 17)
22/10/20 18:16:13 INFO ShuffleBlockFetcherIterator: Getting 4 (112.9 KiB) non-empty blocks including 4 (112.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
22/10/20 18:16:13 INFO Executor: Finished task 0.0 in stage 7.0 (TID 17). 51977 bytes result sent to driver
22/10/20 18:16:13 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 17) in 51 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:13 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
22/10/20 18:16:13 INFO DAGScheduler: ResultStage 7 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38) finished in 0.069 s
22/10/20 18:16:13 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
22/10/20 18:16:13 INFO DAGScheduler: Job 5 finished: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:38, took 0.095523 s
22/10/20 18:16:14 INFO FileSourceStrategy: Pushed Filters: IsNotNull(List Price),IsNotNull(Sale Price)
22/10/20 18:16:14 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(List Price#15),isnotnull(Sale Price#20),(List Price#15 > Sale Price#20)
22/10/20 18:16:14 INFO FileSourceStrategy: Output Data Schema: struct<List Price: string, Product Name: string, Sale Price: string ... 1 more fields>
22/10/20 18:16:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:14 INFO CodeGenerator: Code generated in 40.025496 ms
22/10/20 18:16:14 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 199.0 KiB, free 433.4 MiB)
22/10/20 18:16:14 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 433.4 MiB)
22/10/20 18:16:14 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.2 MiB)
22/10/20 18:16:14 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
22/10/20 18:16:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:14 INFO DAGScheduler: Registering RDD 24 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
22/10/20 18:16:14 INFO DAGScheduler: Got map stage job 6 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
22/10/20 18:16:14 INFO DAGScheduler: Final stage: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0)
22/10/20 18:16:14 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:14 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:14 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
22/10/20 18:16:14 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.6 KiB, free 433.4 MiB)
22/10/20 18:16:14 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.6 KiB, free 433.3 MiB)
22/10/20 18:16:14 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.1.72:39637 (size: 14.6 KiB, free: 434.2 MiB)
22/10/20 18:16:14 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:14 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[24] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:14 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks resource profile 0
22/10/20 18:16:14 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 18) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:14 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 19) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:14 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 20) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:14 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 21) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:14 INFO Executor: Running task 1.0 in stage 8.0 (TID 19)
22/10/20 18:16:14 INFO Executor: Running task 2.0 in stage 8.0 (TID 20)
22/10/20 18:16:14 INFO Executor: Running task 3.0 in stage 8.0 (TID 21)
22/10/20 18:16:14 INFO Executor: Running task 0.0 in stage 8.0 (TID 18)
22/10/20 18:16:14 INFO CodeGenerator: Code generated in 24.1589 ms
22/10/20 18:16:14 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:14 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:14 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:14 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:14 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.1.72:39637 in memory (size: 18.1 KiB, free: 434.2 MiB)
22/10/20 18:16:14 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.1.72:39637 in memory (size: 16.8 KiB, free: 434.3 MiB)
22/10/20 18:16:14 INFO Executor: Finished task 3.0 in stage 8.0 (TID 21). 2826 bytes result sent to driver
22/10/20 18:16:14 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 21) in 272 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:14 INFO Executor: Finished task 0.0 in stage 8.0 (TID 18). 2826 bytes result sent to driver
22/10/20 18:16:14 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 18) in 317 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:14 INFO Executor: Finished task 2.0 in stage 8.0 (TID 20). 2826 bytes result sent to driver
22/10/20 18:16:14 INFO Executor: Finished task 1.0 in stage 8.0 (TID 19). 2826 bytes result sent to driver
22/10/20 18:16:14 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 20) in 323 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:14 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 19) in 324 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:14 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
22/10/20 18:16:14 INFO DAGScheduler: ShuffleMapStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0.340 s
22/10/20 18:16:14 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:14 INFO DAGScheduler: running: Set()
22/10/20 18:16:14 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:14 INFO DAGScheduler: failed: Set()
22/10/20 18:16:14 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
22/10/20 18:16:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:14 INFO CodeGenerator: Code generated in 40.173718 ms
22/10/20 18:16:14 INFO DAGScheduler: Registering RDD 27 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
22/10/20 18:16:14 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/10/20 18:16:14 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)
22/10/20 18:16:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
22/10/20 18:16:14 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:14 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
22/10/20 18:16:14 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 39.4 KiB, free 433.4 MiB)
22/10/20 18:16:14 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 18.3 KiB, free 433.4 MiB)
22/10/20 18:16:14 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.1.72:39637 (size: 18.3 KiB, free: 434.2 MiB)
22/10/20 18:16:14 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:14 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[27] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:14 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
22/10/20 18:16:14 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/10/20 18:16:14 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
22/10/20 18:16:14 INFO ShuffleBlockFetcherIterator: Getting 4 (63.4 KiB) non-empty blocks including 4 (63.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
22/10/20 18:16:14 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 4368 bytes result sent to driver
22/10/20 18:16:14 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 48 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:14 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
22/10/20 18:16:14 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.073 s
22/10/20 18:16:14 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:14 INFO DAGScheduler: running: Set()
22/10/20 18:16:14 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:14 INFO DAGScheduler: failed: Set()
22/10/20 18:16:14 INFO CodeGenerator: Code generated in 19.148905 ms
22/10/20 18:16:15 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
22/10/20 18:16:15 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/10/20 18:16:15 INFO DAGScheduler: Final stage: ResultStage 13 (count at NativeMethodAccessorImpl.java:0)
22/10/20 18:16:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
22/10/20 18:16:15 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:15 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
22/10/20 18:16:15 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 11.1 KiB, free 433.4 MiB)
22/10/20 18:16:15 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 433.4 MiB)
22/10/20 18:16:15 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.1.72:39637 (size: 5.5 KiB, free: 434.2 MiB)
22/10/20 18:16:15 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[30] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:15 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
22/10/20 18:16:15 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 23) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/10/20 18:16:15 INFO Executor: Running task 0.0 in stage 13.0 (TID 23)
22/10/20 18:16:15 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
22/10/20 18:16:15 INFO Executor: Finished task 0.0 in stage 13.0 (TID 23). 2656 bytes result sent to driver
22/10/20 18:16:15 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 23) in 16 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:15 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
22/10/20 18:16:15 INFO DAGScheduler: ResultStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.025 s
22/10/20 18:16:15 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
22/10/20 18:16:15 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.032554 s
The number of product names whose list price is greater than sales price is 544
22/10/20 18:16:15 INFO FileSourceStrategy: Pushed Filters: Or(StringContains(Category,Women),StringContains(Category,women))
22/10/20 18:16:15 INFO FileSourceStrategy: Post-Scan Filters: (Contains(Category#10, Women) OR Contains(Category#10, women))
22/10/20 18:16:15 INFO FileSourceStrategy: Output Data Schema: struct<Category: string, Product Name: string>
22/10/20 18:16:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:15 INFO CodeGenerator: Code generated in 38.569671 ms
22/10/20 18:16:15 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 199.0 KiB, free 433.2 MiB)
22/10/20 18:16:15 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 433.1 MiB)
22/10/20 18:16:15 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.2 MiB)
22/10/20 18:16:15 INFO SparkContext: Created broadcast 14 from toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69
22/10/20 18:16:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:15 INFO DAGScheduler: Registering RDD 34 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69) as input to shuffle 4
22/10/20 18:16:15 INFO DAGScheduler: Got map stage job 9 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69) with 4 output partitions
22/10/20 18:16:15 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69)
22/10/20 18:16:15 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:15 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:15 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[34] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69), which has no missing parents
22/10/20 18:16:15 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 31.8 KiB, free 433.1 MiB)
22/10/20 18:16:15 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 433.1 MiB)
22/10/20 18:16:15 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.1.72:39637 (size: 14.7 KiB, free: 434.2 MiB)
22/10/20 18:16:15 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:15 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[34] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:15 INFO TaskSchedulerImpl: Adding task set 14.0 with 4 tasks resource profile 0
22/10/20 18:16:15 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 24) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:15 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 25) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:15 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 26) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:15 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 27) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:15 INFO Executor: Running task 1.0 in stage 14.0 (TID 25)
22/10/20 18:16:15 INFO Executor: Running task 0.0 in stage 14.0 (TID 24)
22/10/20 18:16:15 INFO Executor: Running task 2.0 in stage 14.0 (TID 26)
22/10/20 18:16:15 INFO Executor: Running task 3.0 in stage 14.0 (TID 27)
22/10/20 18:16:15 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:15 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:15 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:15 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:15 INFO CodeGenerator: Code generated in 18.875995 ms
22/10/20 18:16:15 INFO Executor: Finished task 3.0 in stage 14.0 (TID 27). 2783 bytes result sent to driver
22/10/20 18:16:15 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 27) in 365 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:15 INFO Executor: Finished task 0.0 in stage 14.0 (TID 24). 2783 bytes result sent to driver
22/10/20 18:16:15 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 24) in 579 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:15 INFO Executor: Finished task 1.0 in stage 14.0 (TID 25). 2783 bytes result sent to driver
22/10/20 18:16:15 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 25) in 585 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:15 INFO Executor: Finished task 2.0 in stage 14.0 (TID 26). 2783 bytes result sent to driver
22/10/20 18:16:15 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 26) in 650 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:15 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
22/10/20 18:16:15 INFO DAGScheduler: ShuffleMapStage 14 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69) finished in 0.669 s
22/10/20 18:16:15 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:15 INFO DAGScheduler: running: Set()
22/10/20 18:16:15 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:15 INFO DAGScheduler: failed: Set()
22/10/20 18:16:15 INFO ShufflePartitionsUtil: For shuffle(4), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
22/10/20 18:16:15 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:16 INFO SparkContext: Starting job: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69
22/10/20 18:16:16 INFO DAGScheduler: Got job 10 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69) with 1 output partitions
22/10/20 18:16:16 INFO DAGScheduler: Final stage: ResultStage 16 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69)
22/10/20 18:16:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
22/10/20 18:16:16 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:16 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[37] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69), which has no missing parents
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 35.4 KiB, free 433.1 MiB)
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 433.0 MiB)
22/10/20 18:16:16 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.1.72:39637 (size: 16.5 KiB, free: 434.2 MiB)
22/10/20 18:16:16 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[37] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:16 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
22/10/20 18:16:16 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 28) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/10/20 18:16:16 INFO Executor: Running task 0.0 in stage 16.0 (TID 28)
22/10/20 18:16:16 INFO ShuffleBlockFetcherIterator: Getting 4 (20.6 KiB) non-empty blocks including 4 (20.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
22/10/20 18:16:16 INFO Executor: Finished task 0.0 in stage 16.0 (TID 28). 12877 bytes result sent to driver
22/10/20 18:16:16 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 28) in 27 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:16 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
22/10/20 18:16:16 INFO DAGScheduler: ResultStage 16 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69) finished in 0.041 s
22/10/20 18:16:16 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
22/10/20 18:16:16 INFO DAGScheduler: Job 10 finished: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:69, took 0.052992 s
22/10/20 18:16:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Available),EqualTo(Available,FALSE)
22/10/20 18:16:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Available#8),(Available#8 = FALSE)
22/10/20 18:16:16 INFO FileSourceStrategy: Output Data Schema: struct<Available: string, Product Name: string>
22/10/20 18:16:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:16 INFO CodeGenerator: Code generated in 38.131747 ms
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 199.0 KiB, free 432.9 MiB)
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 432.8 MiB)
22/10/20 18:16:16 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.1 MiB)
22/10/20 18:16:16 INFO SparkContext: Created broadcast 17 from toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81
22/10/20 18:16:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:16 INFO DAGScheduler: Registering RDD 41 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81) as input to shuffle 5
22/10/20 18:16:16 INFO DAGScheduler: Got map stage job 11 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81) with 4 output partitions
22/10/20 18:16:16 INFO DAGScheduler: Final stage: ShuffleMapStage 17 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81)
22/10/20 18:16:16 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:16 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:16 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[41] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81), which has no missing parents
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 31.2 KiB, free 432.8 MiB)
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 432.8 MiB)
22/10/20 18:16:16 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.1.72:39637 (size: 14.5 KiB, free: 434.1 MiB)
22/10/20 18:16:16 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:16 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[41] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:16 INFO TaskSchedulerImpl: Adding task set 17.0 with 4 tasks resource profile 0
22/10/20 18:16:16 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 29) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:16 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 30) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:16 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 31) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:16 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 32) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:16 INFO Executor: Running task 1.0 in stage 17.0 (TID 30)
22/10/20 18:16:16 INFO Executor: Running task 2.0 in stage 17.0 (TID 31)
22/10/20 18:16:16 INFO Executor: Running task 0.0 in stage 17.0 (TID 29)
22/10/20 18:16:16 INFO Executor: Running task 3.0 in stage 17.0 (TID 32)
22/10/20 18:16:16 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:16 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:16 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:16 INFO CodeGenerator: Code generated in 18.476529 ms
22/10/20 18:16:16 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:16 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.1.72:39637 in memory (size: 16.5 KiB, free: 434.1 MiB)
22/10/20 18:16:16 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.1.72:39637 in memory (size: 14.6 KiB, free: 434.1 MiB)
22/10/20 18:16:16 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.1.72:39637 in memory (size: 14.7 KiB, free: 434.2 MiB)
22/10/20 18:16:16 INFO Executor: Finished task 3.0 in stage 17.0 (TID 32). 2826 bytes result sent to driver
22/10/20 18:16:16 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 32) in 408 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:16 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.1.72:39637 in memory (size: 18.3 KiB, free: 434.2 MiB)
22/10/20 18:16:16 INFO Executor: Finished task 2.0 in stage 17.0 (TID 31). 2826 bytes result sent to driver
22/10/20 18:16:16 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 31) in 430 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:16 INFO Executor: Finished task 0.0 in stage 17.0 (TID 29). 2826 bytes result sent to driver
22/10/20 18:16:16 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 29) in 441 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:16 INFO Executor: Finished task 1.0 in stage 17.0 (TID 30). 2826 bytes result sent to driver
22/10/20 18:16:16 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 30) in 451 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:16 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
22/10/20 18:16:16 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.1.72:39637 in memory (size: 33.9 KiB, free: 434.2 MiB)
22/10/20 18:16:16 INFO DAGScheduler: ShuffleMapStage 17 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81) finished in 0.473 s
22/10/20 18:16:16 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:16 INFO DAGScheduler: running: Set()
22/10/20 18:16:16 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:16 INFO DAGScheduler: failed: Set()
22/10/20 18:16:16 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
22/10/20 18:16:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:16 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.1.72:39637 in memory (size: 5.5 KiB, free: 434.2 MiB)
22/10/20 18:16:16 INFO SparkContext: Starting job: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81
22/10/20 18:16:16 INFO DAGScheduler: Got job 12 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81) with 1 output partitions
22/10/20 18:16:16 INFO DAGScheduler: Final stage: ResultStage 19 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81)
22/10/20 18:16:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
22/10/20 18:16:16 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:16 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[44] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81), which has no missing parents
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 35.5 KiB, free 433.2 MiB)
22/10/20 18:16:16 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 433.2 MiB)
22/10/20 18:16:16 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.1.72:39637 (size: 16.5 KiB, free: 434.2 MiB)
22/10/20 18:16:16 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[44] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:16 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
22/10/20 18:16:16 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 33) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/10/20 18:16:16 INFO Executor: Running task 0.0 in stage 19.0 (TID 33)
22/10/20 18:16:16 INFO ShuffleBlockFetcherIterator: Getting 4 (175.5 KiB) non-empty blocks including 4 (175.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
22/10/20 18:16:17 INFO Executor: Finished task 0.0 in stage 19.0 (TID 33). 103525 bytes result sent to driver
22/10/20 18:16:17 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 33) in 46 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:17 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
22/10/20 18:16:17 INFO DAGScheduler: ResultStage 19 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81) finished in 0.059 s
22/10/20 18:16:17 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 19: Stage finished
22/10/20 18:16:17 INFO DAGScheduler: Job 12 finished: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:81, took 0.070624 s
22/10/20 18:16:17 INFO FileSourceStrategy: Pushed Filters: IsNotNull(Available),EqualTo(Available,TRUE)
22/10/20 18:16:17 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(Available#8),(Available#8 = TRUE)
22/10/20 18:16:17 INFO FileSourceStrategy: Output Data Schema: struct<Available: string, Product Name: string>
22/10/20 18:16:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:17 INFO CodeGenerator: Code generated in 29.036358 ms
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 199.0 KiB, free 433.0 MiB)
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 432.9 MiB)
22/10/20 18:16:17 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.2 MiB)
22/10/20 18:16:17 INFO SparkContext: Created broadcast 20 from count at NativeMethodAccessorImpl.java:0
22/10/20 18:16:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:17 INFO DAGScheduler: Registering RDD 48 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
22/10/20 18:16:17 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 4 output partitions
22/10/20 18:16:17 INFO DAGScheduler: Final stage: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:0)
22/10/20 18:16:17 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:17 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:17 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 31.1 KiB, free 432.9 MiB)
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 14.5 KiB, free 432.9 MiB)
22/10/20 18:16:17 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.1.72:39637 (size: 14.5 KiB, free: 434.2 MiB)
22/10/20 18:16:17 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:17 INFO TaskSchedulerImpl: Adding task set 20.0 with 4 tasks resource profile 0
22/10/20 18:16:17 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 34) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 35) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 36) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 37) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO Executor: Running task 0.0 in stage 20.0 (TID 34)
22/10/20 18:16:17 INFO Executor: Running task 1.0 in stage 20.0 (TID 35)
22/10/20 18:16:17 INFO Executor: Running task 2.0 in stage 20.0 (TID 36)
22/10/20 18:16:17 INFO Executor: Running task 3.0 in stage 20.0 (TID 37)
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:17 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.1.72:39637 in memory (size: 14.5 KiB, free: 434.2 MiB)
22/10/20 18:16:17 INFO Executor: Finished task 3.0 in stage 20.0 (TID 37). 2826 bytes result sent to driver
22/10/20 18:16:17 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 37) in 219 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:17 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.1.72:39637 in memory (size: 16.5 KiB, free: 434.2 MiB)
22/10/20 18:16:17 INFO Executor: Finished task 1.0 in stage 20.0 (TID 35). 2826 bytes result sent to driver
22/10/20 18:16:17 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 35) in 264 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:17 INFO Executor: Finished task 0.0 in stage 20.0 (TID 34). 2826 bytes result sent to driver
22/10/20 18:16:17 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 34) in 303 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:17 INFO Executor: Finished task 2.0 in stage 20.0 (TID 36). 2826 bytes result sent to driver
22/10/20 18:16:17 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 36) in 306 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:17 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
22/10/20 18:16:17 INFO DAGScheduler: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:0) finished in 0.320 s
22/10/20 18:16:17 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:17 INFO DAGScheduler: running: Set()
22/10/20 18:16:17 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:17 INFO DAGScheduler: failed: Set()
22/10/20 18:16:17 INFO ShufflePartitionsUtil: For shuffle(6), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
22/10/20 18:16:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:17 INFO DAGScheduler: Registering RDD 51 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
22/10/20 18:16:17 INFO DAGScheduler: Got map stage job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/10/20 18:16:17 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0)
22/10/20 18:16:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 21)
22/10/20 18:16:17 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:17 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 38.7 KiB, free 433.0 MiB)
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 18.1 KiB, free 432.9 MiB)
22/10/20 18:16:17 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.1.72:39637 (size: 18.1 KiB, free: 434.2 MiB)
22/10/20 18:16:17 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:17 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
22/10/20 18:16:17 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 38) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO Executor: Running task 0.0 in stage 22.0 (TID 38)
22/10/20 18:16:17 INFO ShuffleBlockFetcherIterator: Getting 4 (229.2 KiB) non-empty blocks including 4 (229.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
22/10/20 18:16:17 INFO Executor: Finished task 0.0 in stage 22.0 (TID 38). 4368 bytes result sent to driver
22/10/20 18:16:17 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 38) in 46 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:17 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
22/10/20 18:16:17 INFO DAGScheduler: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.060 s
22/10/20 18:16:17 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:17 INFO DAGScheduler: running: Set()
22/10/20 18:16:17 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:17 INFO DAGScheduler: failed: Set()
22/10/20 18:16:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
22/10/20 18:16:17 INFO DAGScheduler: Got job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
22/10/20 18:16:17 INFO DAGScheduler: Final stage: ResultStage 25 (count at NativeMethodAccessorImpl.java:0)
22/10/20 18:16:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
22/10/20 18:16:17 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:17 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 11.1 KiB, free 432.9 MiB)
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 432.9 MiB)
22/10/20 18:16:17 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.1.72:39637 (size: 5.5 KiB, free: 434.2 MiB)
22/10/20 18:16:17 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:17 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
22/10/20 18:16:17 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 39) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO Executor: Running task 0.0 in stage 25.0 (TID 39)
22/10/20 18:16:17 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
22/10/20 18:16:17 INFO Executor: Finished task 0.0 in stage 25.0 (TID 39). 2656 bytes result sent to driver
22/10/20 18:16:17 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 39) in 16 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:17 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
22/10/20 18:16:17 INFO DAGScheduler: ResultStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.035 s
22/10/20 18:16:17 INFO DAGScheduler: Job 15 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 25: Stage finished
22/10/20 18:16:17 INFO DAGScheduler: Job 15 finished: count at NativeMethodAccessorImpl.java:0, took 0.042861 s
No. of product which are available is 2259
22/10/20 18:16:17 INFO FileSourceStrategy: Pushed Filters: Or(StringContains(Description,Nylon),StringContains(Description,nylon))
22/10/20 18:16:17 INFO FileSourceStrategy: Post-Scan Filters: (Contains(Description#12, Nylon) OR Contains(Description#12, nylon))
22/10/20 18:16:17 INFO FileSourceStrategy: Output Data Schema: struct<Description: string, Product Name: string>
22/10/20 18:16:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 199.0 KiB, free 432.7 MiB)
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 33.9 KiB, free 432.7 MiB)
22/10/20 18:16:17 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.1.72:39637 (size: 33.9 KiB, free: 434.1 MiB)
22/10/20 18:16:17 INFO SparkContext: Created broadcast 24 from toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107
22/10/20 18:16:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 12569037 bytes, open cost is considered as scanning 4194304 bytes.
22/10/20 18:16:17 INFO DAGScheduler: Registering RDD 58 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107) as input to shuffle 8
22/10/20 18:16:17 INFO DAGScheduler: Got map stage job 16 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107) with 4 output partitions
22/10/20 18:16:17 INFO DAGScheduler: Final stage: ShuffleMapStage 26 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107)
22/10/20 18:16:17 INFO DAGScheduler: Parents of final stage: List()
22/10/20 18:16:17 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:17 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[58] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107), which has no missing parents
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 31.8 KiB, free 432.7 MiB)
22/10/20 18:16:17 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 14.7 KiB, free 432.6 MiB)
22/10/20 18:16:17 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 192.168.1.72:39637 (size: 14.7 KiB, free: 434.1 MiB)
22/10/20 18:16:17 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[58] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
22/10/20 18:16:17 INFO TaskSchedulerImpl: Adding task set 26.0 with 4 tasks resource profile 0
22/10/20 18:16:17 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 40) (192.168.1.72, executor driver, partition 0, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 41) (192.168.1.72, executor driver, partition 1, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 42) (192.168.1.72, executor driver, partition 2, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 43) (192.168.1.72, executor driver, partition 3, PROCESS_LOCAL, 4982 bytes) taskResourceAssignments Map()
22/10/20 18:16:17 INFO Executor: Running task 0.0 in stage 26.0 (TID 40)
22/10/20 18:16:17 INFO Executor: Running task 2.0 in stage 26.0 (TID 42)
22/10/20 18:16:17 INFO Executor: Running task 3.0 in stage 26.0 (TID 43)
22/10/20 18:16:17 INFO Executor: Running task 1.0 in stage 26.0 (TID 41)
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 37707111-46081845, partition values: [empty row]
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 25138074-37707111, partition values: [empty row]
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 12569037-25138074, partition values: [empty row]
22/10/20 18:16:17 INFO FileScanRDD: Reading File path: file:///home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart_ecommerce_product_details.json, range: 0-12569037, partition values: [empty row]
22/10/20 18:16:18 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 192.168.1.72:39637 in memory (size: 5.5 KiB, free: 434.1 MiB)
22/10/20 18:16:18 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 192.168.1.72:39637 in memory (size: 18.1 KiB, free: 434.1 MiB)
22/10/20 18:16:18 INFO Executor: Finished task 3.0 in stage 26.0 (TID 43). 2826 bytes result sent to driver
22/10/20 18:16:18 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 43) in 209 ms on 192.168.1.72 (executor driver) (1/4)
22/10/20 18:16:18 INFO Executor: Finished task 1.0 in stage 26.0 (TID 41). 2826 bytes result sent to driver
22/10/20 18:16:18 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 41) in 269 ms on 192.168.1.72 (executor driver) (2/4)
22/10/20 18:16:18 INFO Executor: Finished task 0.0 in stage 26.0 (TID 40). 2826 bytes result sent to driver
22/10/20 18:16:18 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 40) in 277 ms on 192.168.1.72 (executor driver) (3/4)
22/10/20 18:16:18 INFO Executor: Finished task 2.0 in stage 26.0 (TID 42). 2826 bytes result sent to driver
22/10/20 18:16:18 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 42) in 291 ms on 192.168.1.72 (executor driver) (4/4)
22/10/20 18:16:18 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
22/10/20 18:16:18 INFO DAGScheduler: ShuffleMapStage 26 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107) finished in 0.301 s
22/10/20 18:16:18 INFO DAGScheduler: looking for newly runnable stages
22/10/20 18:16:18 INFO DAGScheduler: running: Set()
22/10/20 18:16:18 INFO DAGScheduler: waiting: Set()
22/10/20 18:16:18 INFO DAGScheduler: failed: Set()
22/10/20 18:16:18 INFO ShufflePartitionsUtil: For shuffle(8), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
22/10/20 18:16:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
22/10/20 18:16:18 INFO SparkContext: Starting job: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107
22/10/20 18:16:18 INFO DAGScheduler: Got job 17 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107) with 1 output partitions
22/10/20 18:16:18 INFO DAGScheduler: Final stage: ResultStage 28 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107)
22/10/20 18:16:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
22/10/20 18:16:18 INFO DAGScheduler: Missing parents: List()
22/10/20 18:16:18 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[61] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107), which has no missing parents
22/10/20 18:16:18 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 35.4 KiB, free 432.7 MiB)
22/10/20 18:16:18 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 16.5 KiB, free 432.7 MiB)
22/10/20 18:16:18 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 192.168.1.72:39637 (size: 16.5 KiB, free: 434.1 MiB)
22/10/20 18:16:18 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1513
22/10/20 18:16:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[61] at toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107) (first 15 tasks are for partitions Vector(0))
22/10/20 18:16:18 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
22/10/20 18:16:18 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 44) (192.168.1.72, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
22/10/20 18:16:18 INFO Executor: Running task 0.0 in stage 28.0 (TID 44)
22/10/20 18:16:18 INFO ShuffleBlockFetcherIterator: Getting 4 (65.2 KiB) non-empty blocks including 4 (65.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
22/10/20 18:16:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
22/10/20 18:16:18 INFO Executor: Finished task 0.0 in stage 28.0 (TID 44). 51785 bytes result sent to driver
22/10/20 18:16:18 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 44) in 19 ms on 192.168.1.72 (executor driver) (1/1)
22/10/20 18:16:18 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
22/10/20 18:16:18 INFO DAGScheduler: ResultStage 28 (toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107) finished in 0.028 s
22/10/20 18:16:18 INFO DAGScheduler: Job 17 is finished. Cancelling potential speculative or zombie tasks for this job
22/10/20 18:16:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 28: Stage finished
22/10/20 18:16:18 INFO DAGScheduler: Job 17 finished: toPandas at /home/prasag/Desktop/Fuse/spark/Assignment/walmart_ecommerce_product_details/walmart ecommerce assignment(to csv).py:107, took 0.035634 s
22/10/20 18:16:18 INFO SparkContext: Invoking stop() from shutdown hook
22/10/20 18:16:18 INFO SparkUI: Stopped Spark web UI at http://192.168.1.72:4042
22/10/20 18:16:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
22/10/20 18:16:18 INFO MemoryStore: MemoryStore cleared
22/10/20 18:16:18 INFO BlockManager: BlockManager stopped
22/10/20 18:16:18 INFO BlockManagerMaster: BlockManagerMaster stopped
22/10/20 18:16:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
22/10/20 18:16:18 INFO SparkContext: Successfully stopped SparkContext
22/10/20 18:16:18 INFO ShutdownHookManager: Shutdown hook called
22/10/20 18:16:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-ca79fff1-2930-47ce-8224-7ff0c5eeae91
22/10/20 18:16:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-ca79fff1-2930-47ce-8224-7ff0c5eeae91/pyspark-e70922c7-cf23-47da-9148-a9c7a834021a
22/10/20 18:16:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-aca54839-4463-4d5d-b62f-5a047271fc01
